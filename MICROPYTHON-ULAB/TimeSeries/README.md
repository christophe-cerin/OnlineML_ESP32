# Time series

This page relates batch and Extreme-edge incremental learning for time series analysis. The latter is based on offline / batch learning method, but considering a 'sliding window' and not the full data.

We provide experimental results, based on random generated data or real data from an outside building (`TourPerretNoHeader.csv`). The humidity attribute of the dataset corresponds to the observed data for the building. We do forecasting for this attribute.

## Batch learning and time series

You will find three types of methods: LSTM (Long short-term memory) and BI-LSTM (bidirectional long short-term memory), PROPHET, and TBATS (Trigonometric Box-Cox transform, ARMA errors, Trend, and Seasonal components). 

- Long short-term memory (LSTM)is a type of recurrent neural network (RNN) aimed at mitigating the vanishing gradient problem[2] commonly encountered by traditional RNNs.
- Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series with strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.
- TBATS model is a powerful method for time series forecasting that can handle multiple seasonalities and complex patterns.

Figure 1 illustrates the humidity values over 360 time intervals, represented by the plot in red. The green and blue lines indicate the training data, while the grey line represents the predictions. The Python code adheres to traditional methodologies. Once the dataset is prepared, it is imperative to partition it into training and testing subsets to assess the model's performance on data unseen during training. Subsequently, a Long Short-Term Memory (LSTM) model is employed. Upon fitting the model with the training data, predictions are generated on the test set. This approach provides insights into the model's efficacy in forecasting humidity based on novel input data.

Note that the computing time for learning the 360 time intervals is about 35s on a Macbook Air equipped with 24MB of RAM and an M3 processor.
  
<br>  

<figure>
  <img src="Images/LSTM.png" alt="My image caption">
  <figcaption><b>Fig. 1:</b> Exploring Tour Perret dataset with LSTM</figcaption>
</figure>
  
<br>  
  
Figure 2 illustrates a periodic signal subjected to 'noise' interference. The green line, labeled 'Pure Prophet,' depicts the prediction generated by our Python implementation of the PROPHET algorithm. Conversely, the blue line, labeled 'Prophet Lib,' represents the forecast obtained using the `prophet` library within the same test dataset. While the `prophet` library offers a broader range of functionalities and demands less parameter tuning compared to our version, it is noteworthy that our implementation is fully self-contained and independent of external libraries.

<figure>
  <img src="Images/PROPHET.png" alt="My image caption">
  <figcaption><b>Fig. 2:</b> Exploring a random generated dataset with PROPHET</figcaption>
</figure>


## Extreme-edge incremental learning and time series
