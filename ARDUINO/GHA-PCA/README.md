## Generalized Hebbian  Algorithm  (GHA)

The Generalized Hebbian Algorithm is a neural variant of PCA developed by Sanger under the name of Generalized Hebbian Algorithm (GHA). The GHA algorithm has been generally applied to image processing, in particular for image compression with minimal loss of information (optimal coding). The GHA allows to extract the principal components of very large vectors characteristic of the data such as the dimension of the representation. It also calculates only the first principal components (the most important), which can represent a significant saving in computation. The adaptive nature of the algorithm also allows to be satisfied with an approximate estimate of the results (which can be refined later if necessary), whereas standard PCA software calculates all the eigenvectors even if it is with the maximum precision.

However, GHA has some drawbacks. As is often the case with neural techniques, the learning step must be estimated empirically, and learning times can be long if we are looking for good precision, especially for the following components with lower variance. And this algorithm causes calculation errors to accumulate from one neuron to the next, which inevitably reduces the precision of the successive components. It is therefore important in practice to limit ourselves to the first principal components. It should be remembered that the algorithm does not directly give the share of variance corresponding to each principal component. We can then easily calculate the output variance of each neuron on a sample of the corpus in order to find the number of components that are actually useful (we will stop learning new neurons when their variance becomes insufficient).

In short, AHG is only justified when we can be satisfied with the first principal components. But this is often the case, since they represent the largest part of the information contained in the data. Finally, like PCA, HGA is a purely linear method that can only capture linear correlations between data (this is actually equivalent to using only covariance).

This is probably sufficient for processing documents, but if one wants to overcome this limitation, one should consider other methods such as Independent Component Analysis (see HÃ©rault & Jutten 1994) or Kohonen Maps (Ritter & Kohonen 1989)(Kohonen 1998).
